\documentclass[twoside]{article}

\usepackage[math]{kurier}
\usepackage[sc]{mathpazo}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}
\renewcommand{\sfdefault}{kurier}

\usepackage[boxruled]{algorithm2e}
\usepackage[utf8]{inputenc}
\usepackage[backend=biber]{biblatex}
\usepackage[english]{babel}
\usepackage[english]{babel}
\usepackage[autostyle]{csquotes}
\usepackage{placeins}
\usepackage[backend=biber]{biblatex}
\bibliography{./lecture_11_biblio_.bib}

\usepackage{graphics}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{float}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}


\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}


\newcommand{\lecture}[3]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf \sffamily AA 274: Principles of Robotic Autonomy
                        \hfill Winter 2018} }
       \vspace{4mm}
       \hbox to 6.28in { {\sffamily{\Large \hfill Lecture #1: #2  \hfill}} }
       \vspace{2mm}
       % \hbox to 6.28in { {\it \hfill Scribes: #4} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Lecture #1: #2}{Lecture #1: #2}

   \vspace*{4mm}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%
%document
\begin{document}
%modify this
\lecture{11}{Localization Filters}{}

\section{Introduction}

Last lecture, we discussed the Bayes filter to continuously update our belief on something, for example, a robot's location. However, because the Bayes filter requires iterating over a continuous variable, it is generally impracticable due to computational limits.

\par
The first part of this lecture covers filtering techniques which are based on the Bayes filter but which make certain approximations which render these filters practically implementable, which the Bayes filter is not. We discuss two main classes of filter: parametric filters, and non-parametric filters. {\it Parametric} filters generally begin by restricting the belief of the Bayes filter to a particular distribution, such as a Gaussian, and proceeding to estimate the {\it parameters} determining this specific distribution, such as the mean and variance in the case of Gaussian. In {\it non-parametric} filters, on the other hand, we make no restrictive assumption as to the distribution of the belief; rather, we discretize the belief into ``particles," thus replacing the continuous variable in the Bayes filter iteration with a discrete variable and thus making the iteration practicable. Thus while both parametric and non-parametric filters are based on the Bayes filter, they make completely orthogonal simplifying assumptions, and thus we should expect the error source for each to be different as well: for parametric filters, errors will arise from our initial restriction on the possible belief, for non-parametric filters, errors will arise due to the discretization.

\par
The second part of this lecture is a brief introduction to robot localization.

\section{Parametric Filters}
Parametric filters are a family of state estimators that assume the form of a robot's belief distribution and calculate the parameters to fully define that distribution based on the latest information. In particular, Gaussian filters are an important group of parametric filters that assume the belief distribution is a multivariate normal distribution. The Kalman filter and its variants belong to this group of parametric filters.

%\FloatBarrier
\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{gaussian_univariate.png}
  \caption{Gaussian Distribution in One Variable}
  \label{fig:EKF_best}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{gaussian_multivariate.png}
  \caption{Level Curves of Gaussian Distribution in Two Variables}
  \label{fig:EKF_bad}
\end{subfigure}
\caption{Visualizations of the multivariate normal (Gaussian) distribution \cite{Xmisc}.}
\label{fig:Gaussians}
\end{figure}
%\FloatBarrier

\subsection{Kalman Filter}
\subsubsection{Setup}
The Kalman filter uses a model of the system dynamics, known control inputs to a system, and noisy measurements to estimate the robot's state. The algorithm calculates a belief on the state predicted from the model and then updates this belief to be in closer accord with the actual observations / measurements. Thus the belief output by a Kalman filter is informed both by our prior belief (past observations / assumptions) and our observations (current noisy measurements).

\par
The key idea behind Kalman filters is that we assume that each belief function (the expected state) follows a multivariate normal distribution (Gaussian distribution), illustrated in Figure \ref{fig:Gaussians}. While we could in theory choose another distribution, Gaussians are convenient for two reasons: $(1)$ assuming the Gaussian is computationally convenient as it produces a closed form solution for updating the Kalman filter, and $(2)$ the Law of Large Numbers suggests that assuming a Gaussian distribution is probably reasonable in most cases. There are instances, however, where this assumption is poor and leads to complications: for example, when a robot is first turned on and has no idea where it is, the uni-modal Gaussian assumption is clearly poor..

%However, instead of propagating the probability density function itself, we choose to propagate forward the project state (mean) and covariance.

\par
Before proceeding into the details of the Kalman filter, let us briefly discuss the assumptions we will make to simplify our analysis. The first, as previously mentioned, is that our belief state is Gaussian. We will use three properties of Gaussian random variables.
\begin{enumerate}
    \item If $X \sim \mathcal{N}(\mu, \Sigma)$, then
    \[
    Y = AX + b \sim \mathcal{N}(A\mu+b, A\Sigma A^T).
    \]
    \item If $X_i \sim \mathcal{N}(\mu_i, \Sigma_i)$ for $i = 1,2$, and $X_1, X_2$ are independent, then
    \[
    Y = X_1 + X_2 \sim \mathcal{N}(\mu_1 + \mu_2, \Sigma_1 + \Sigma_2).
    \]
    \item The product of Gaussian pdf's is also a Gaussian.
\end{enumerate}

\par
In addition to our Gaussian assumption, we will make three further assumptions on our system itself.
\begin{enumerate}
    \item
    We assume that our robot's state evolves via a linear dynamical system. That is, at time $t$, the state $x_t$ is given by
    \begin{align*}
    x_t = A_t x_{t-1} + B_t u_t + \epsilon_{t},
    \end{align*}
    where $x_{t-1}$ is the previous state, $u_t$ is the most recent control input, and $\epsilon_{t}$ is the independent process noise with distribution $\mathcal{N}(0,R_t)$.
    \item[] {\bf Consequence:}
    Given a particular $x_{t-1},u_t$ and assuming that $\epsilon_t$ is Gaussian (a very standard assumption for noise), $x_t$ is also Gaussian. Specifically, using the properties of Gaussians given above, $$x_t \sim \mathcal{N}(A_t x_{t-1} + B_t u_t, R_t).$$
    
    \item
    We assume that the measurement model is also linear. That is, if we attempt to measure the state of our robot at time $t$ and true state $x_t$, our measurement $z_t$ is given by
    \begin{align*}
    z_t = C_t x_t + \delta_t,
    \end{align*}
    where $\delta_t$ is the independent measurement noise with distribution $\mathcal{N}(0,Q_t)$
    \item[] {\bf Consequence:}
    This ensures the measurement probability is also a Gaussian. Specifically, $$z_t \sim \mathcal{N}(C_t x_t, Q_t).$$
    
    \item
    We assume that the initial belief function is also Gaussian in the form of \begin{align*}
    bel(x_0) = \mathtt{det}(2\pi\Sigma_0)^{-\frac{1}{2}}\mathtt{exp}(-\frac{1}{2}(x_0-\mu_0)\Sigma_0^{-1}(x_0-\mu_0)^{T}).
    \end{align*}
    \item[] {\bf Consequence:} 
    This assumption, in conjunction with the prior two, ensures that all posterior $bel$ functions will also follow Gaussian distribution. As mentioned before, this assumption is sometimes quite poor; however, it drastically reduces the computational complexity of the problem.
\end{enumerate}

Note that, by the union of these three assumption, all belief states throughout time will follow a Gaussian distribution. Since Gaussian distributions are uniquely determined by the first two moments (that is, the mean and the variance), this further means that we need only propagate the mean and the variance (or, in the multivariate case, the covariance matrix) through time rather than a full expression for the pdf.

\subsubsection{Algorithm}
We will now consider the actual algorithm which implements the Kalman filter. As with the more general Bayes filter, the Kalman filter can be broken down into two steps: a {\it prediction} step based on the prior belief and a {\it correction} step based on the most recent measurement (See Fig \ref{fig:KF_pred_corr}).

%\FloatBarrier
\begin{figure}[h]
\centering
  \includegraphics[width=.9\linewidth]{KF_pred_corr.png}
  \caption{Prediction / Correction loop in Kalman Filter}
\label{fig:KF_pred_corr}
\end{figure}
%\FloatBarrier

\par
Note that, by assumptions 1 and 3 given above, we our previous belief state $bel(x_{t-1})$ is known to be Gaussian, and as our process noise $\epsilon(t)$ is also assumed to be Gaussian, $bel(x_t)$ will be Gaussian. Consequently, we need only be provided with $(\mu_{t-1}, \Sigma_{t-1})$ instead of the complete $bel(x_{t-1})$, and we need only estimate $(\mu_{t}, \Sigma_{t})$ instead of the complete $bel(x_{t})$.

\par
First we make a prediction of the state, projecting mean and covariance ahead based on our previous belief state $bel(x_{t-1})$ and our most recent control input $u_t$.
\begin{align}
\begin{split}
\bar{\mu}_t &= A_t\mu_{t-1}+B_t u_t \\
\bar{\Sigma}_t &= A_t\Sigma_{t-1} A_t^{T} + R_t
\end{split}
\label{LinDyn}
\end{align}
Then we need to correct the prediction with our measurement -- that is, we adjust our predicted belief to be more in accord with our most recent observation / measurement $z_t$. First we compute the Kalman gain,
\begin{equation}
K_t = \bar{\Sigma}_{t}C_t^{T}(C_t\bar{\Sigma}_{t}C_t^{T}+Q_t)^{-1}.
\end{equation}
At a high level, the Kalman gain can be thought of as the ratio of how much uncertainty we have in our prediction over how much uncertainty we have in our measurement. Having computed the Kalman gain, we update our belief function via a linear update.
\begin{align}
\begin{split}
\mu_t &= \bar{\mu}_t + K_t(z_t-C_t\bar\mu_{t})\\
\Sigma_t &= (I-C_t K_t)\bar{\Sigma}_t
\end{split}
\label{KF}
\end{align}
That is, we correct our belief by considering the difference between what we actually observed ($z_t$) and what we would have observed had our predicted belief been correct ($C_t\bar\mu_{t}$). As intuition would suggest, if $K_t$ is large, meaning that we have much more uncertainty in our prediction than in our measurement, our correction term is large; if $K_t$ small, meaning that we have much more uncertainty in our measurement than in our prediction, then our correction term is small.

\par
The correction to the covariance matrix is less obvious, but follows from similar logic.

\par
We then repeat this process. A few iterations of this algorithm are depicted in Figure \ref{fig:KF_algorithm}.

\begin{algorithm}[H]
\caption{Kalman Filter}\label{alg:KF}
\begin{algorithmic}[1]
    \State {\bf Data:} $(\mu_{t-1}, \Sigma_{t-1}), u_t, z_t$
    \State {\bf Result: } $\left(\mu_t, \Sigma_t\right)$
    \State $	\bar{\mu}_t = A_t\mu_{t-1}+B_t u_t$
    \Comment{Predict mean}
	\State $	\bar{\Sigma}_t = A_t\Sigma_{t-1} A_t^{T} + R_t$
	\Comment{Predict covar}
	\State $ 	K_t = \bar{\Sigma}_{t}C_t^{T}(C_t\bar{\Sigma}_{t}C_t^{T}+Q_t)^{-1}$
	\Comment{Kalman gain}
	\State $    \mu_t = \bar{\mu}_t K_t(z_t-C_t\bar\mu_{t})$
	\Comment{Correct mean}
	\State $   \Sigma_t = (I-C_t K_t)\bar{\Sigma}_t$
	\Comment{Correct covar}
	\State {\bf Return: } $\left(\mu_t, \Sigma_t\right)$
\end{algorithmic}
\end{algorithm}

%\FloatBarrier
\begin{figure}[tp]
\centering
\includegraphics[width=1\linewidth]{KF_algorithm.png}
\caption{Visualization of the Kalman Filter Algorithm from \cite{thrun2005probabilistic}. Current step is in bold and previous data are in gray: (a) the initial belief distribution, (b) the measurement with uncertainty in bold and initial belief in gray, (c) updated belief in bold with previous belief and measurement in gray, (d) belief after motion to the right with added uncertainty in bold and previous belief in gray, (e) new measurement with uncertainty in bold and latest belief in gray, and (f) the updated belief in bold with previous belief and measurement in gray.}
\label{fig:KF_algorithm}
\end{figure}
%\FloatBarrier

\subsubsection{Derivation}
The following recursive update equation can be derived by applying Bayes rule to the posterior distribution:
\begin{equation}
p(x_t \mid z_{1:t}, u_{1:t}) = \eta p(z_t \mid x_t, z_{1:t-1}, u_{1:t})p(x_t \mid z_{1:t-1}, u_{1:t}).
\end{equation} Note that conditional independence gives the simplification
\begin{equation}
p(x_t \mid z_{1:t}, u_{1:t}) = \eta p(z_t \mid x_t)p(x_t \mid z_{1:t-1}, u_{1:t}). \label{predbel0}
\end{equation}
Given, $\overline{bel}(x_t) = p(x_t \mid z_{1:t-1},u_{1:t})$, we can assume that the state is complete to obtain the recursive update equation:
\begin{equation}
\overline{bel}(x_t) = \int p(x_t \mid x_{t-1}, u_t) p(x_{t-1} \mid z_{1:t-1}u_{1:t-1}) dx_{t-1}
\end{equation}
which can also be expressed as
\begin{equation}
\overline{bel}(x_t) = \int p(x_t \mid x_{t-1}, u_t) bel(x_{t-1}) dx_{t-1} \label{predbel}
\end{equation}
Since $x_t = A_tx_{t-1} + B_tu_t + \epsilon_t$ with $\epsilon_t \sim \mathcal{N}(\mu_t, R_t)$, we know that $p(x_t \mid x_{t-1}, u_t) \sim \mathcal{N}(A_tx_{t-1} + B_tu_t, R_t)$. Similarly, the Linear-Gaussian assumptions described above guarantee that $bel(x_{t-1}) \sim \mathcal{N}(\mu_{t-1}, \Sigma_{t-1}$. Then \eqref{predbel} can be simplified to
\begin{equation}
\overline{bel}(x_t) = \mathcal{N}(\bar{\mu}_t, \bar{\Sigma}_t) \label{predbel2}
\end{equation}
where $\bar{\mu}_t = A_t\mu_{t-1} + B_t u_t$ and $\bar{\Sigma}_t = A_t \Sigma_{t-1} A_t^T + R_t$ from integrating the product of the Gaussian distributions. Thus, the prediction step can be summarized with \eqref{predbel2}.
From \eqref{predbel0}, we have the following relationship between the posterior distribution and the predicted belief:
\begin{equation}
bel(x_t) = \eta p(z_t \mid x_t) \overline{bel}(x_t).
\end{equation}
The assumptions of a linear-Gaussian system provide that $p(z_t \mid x_t) \sim \mathcal{N}(Cx_t, Q_t)$ and that $\overline{bel}(x_t) \sim \mathcal{N}(\bar{\mu}_t, \bar{\Sigma}_t)$. Noting that the product of two Gaussians is Gaussian, we have
\begin{equation}
bel(x_t) = \mathcal{N}(\mu_t, \Sigma_t),
\end{equation}
for which the equations for $\mu_t$, and $\Sigma_t$ can be expressed as in \eqref{KF}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Extended Kalman Filter (EKF)}

The Extended Kalman Filter (EKF) is a Kalman Filter that relaxes the linearity assumption of the models. Instead of trying to find the exact posterior solution, it seeks to compute a Gaussian approximation.  The belief distribution is passed through the filter and results in a non-Gaussian distribution. Then we find the best Gaussian fit to this resulting distribution. 

In relaxing the linearity assumption to use the EKF, we now assume that the dynamics of the system are given by
\begin{equation}
    x_t = g(u_t,x_{t-1}) + \epsilon_{t}.
\end{equation}
Furthermore, the measurement model is now given by
\begin{equation}
    z_t = h(x_t) + \delta_{t}.
\end{equation}

\par
A key idea in EKF is that we can use the first-order Taylor expansion to linearize $g$ and $h$ around the most likely state (e.g. the mean of the state), then pass beliefs through linearized models. For the dynamics equation, we propagate the state as $x_t = g(u_t, x_{t-1})$, with $g(u_t, x_{t-1})$ in the form of
\begin{equation}
	g(u_t, x_{t-1}) \approx g(u_t, \mu_{t-1}) + J_g(u_t, \mu_{t-1})(x_{t-1}-\mu_{t-1})
\end{equation}
where $J_g$ is the Jacobian matrix of the function $g$. Using the notation $G_t = J_g(u_t, \mu_{t-1})$, the probability distribution of the state at time $t$ given the state at time $t-1$ and the control action taken at time $t$ is expressed as
\begin{equation}\footnotesize
p(x_t \mid u_t, x_{t-1}) = \det \left(2\pi R_t\right)^{-1/2} \exp \left(-\frac{1}{2}\left[x_t - g(u_t, \mu_{t-1}) - G_t\cdot (x_{t-1} - \mu_{t-1})\right]^T R_t^{-1} \left[x_t - g(u_t, \mu_{t-1}) - G_t\cdot(x_{t-1} - \mu_{t-1})\right]\right)
\end{equation}
And for the measurement model $z_t = h(x_t)$, where
\begin{equation}
	h(x_t) = h(\bar{\mu}_{t})+J_h(\bar{\mu}_{t})(x_t-\bar{\mu}_{t})
\end{equation}
The Jacobian of the measurement function is $J_h({\bar{\mu}_t})$, for which we use the notation $H_t$. Then the probability distribution of the measurement given the state at time $t$ is
\begin{equation}
p(z_t \mid x_t) = \det(2\pi Q_t)^{-1/2} \exp \left( -\frac{1}{2} \left[z_t - h(\bar{\mu}_t) - H_t \cdot (x_t - \bar{\mu}_t)\right]^T Q_t^{-1}\left[z_t - h(\bar{\mu}_t) - H_t \cdot (x_t - \bar{\mu}_t)\right]\right)
\end{equation}

A comparison of the linearity requirement of the standard Kalman Filter and the performance of the EKF on a nonlinear function that violates this requirement is shown in Figure \ref{fig:KF_vs_EKF}.

%\FloatBarrier
\begin{figure}[tp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{KF_linearity.png}
  \caption{Kalman Filter Linearity Assumption}
  \label{fig:KF_linearity}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{EKF_med_var.png}
  \caption{EKF Linearization}
  \label{fig:EKF_med_var}
\end{subfigure}
\caption{Comparison of (a) the linearity assumption of the standard Kalman Filter \cite{Xmisc} and (b) its extension to nonlinear functions through linearization \cite{Xmisc}.}
\label{fig:KF_vs_EKF}
\end{figure}
%\FloatBarrier

\subsubsection{EKF Algorithm}
Unlike ordinary Kalman Filters, the EKF algorithm uses Jacobian matrices of the linearized model $g$ and $h$ instead of the linear system matrices.
In the prediction step we propagate forward the expected value of the state assuming no noise. We also replace the covariance matrix $A_t$ with Jacobian $G_t$ from the linearization. While in the correction step we replace $C_t$ in the Kalman gain with Jacobian $H_t$. The linearized dynamics equations in \eqref{LinDyn} are replaced by the following:
\begin{align}
\begin{split}
\bar{\mu}_t &= g(u_t,\mu_{t-1})
\\\bar{\Sigma}_t &= G_t\Sigma_{t-1} G_t^{T} + R_t
\end{split}
\end{align}
Then we need to correct the prediction with our measurement. First we compute the Kalman gain,
\begin{equation}
K_t = \bar{\Sigma}_{t}H_t^{T}(H_t\bar{\Sigma}_{t}H_t^{T}+Q_t)^{-1}
\end{equation}
Then we update our belief function
\begin{align}
\begin{split}
\mu_t &= \bar{\mu}_t+K_t(z_t-h(\mu_{t})) \\
\Sigma_t &= (I-K_t H_t)\bar{\Sigma}_t
\end{split}
\end{align}
We then repeat this process.

\begin{algorithm}[H]
\caption{Extended Kalman Filter}
\begin{algorithmic}[1]
    \State {\bf Data: }$(\mu_{t-1}, \Sigma_{t-1}), u_t, z_t$
	\State {\bf Result: }$\left(\mu_t, \Sigma_t\right)$
	\State $	\bar{\mu}_t = g(u_t,\mu_{t-1})$\;
	\Comment{Predict mean}
	\State $	\bar{\Sigma}_t = G_t\Sigma_{t-1} G_t^{T} + R_t$\;
	\Comment{Predict covar}
	\State $ 	K_t = \bar{\Sigma}_{t}H_t^{T}(H_t\bar{\Sigma}_{t}H_t^{T}+Q_t)^{-1}$\;
	\Comment{Kalman gain}
	\State $    \mu_t = \bar{\mu}_t+K_t(z_t-h(\mu_{t}))$\;
	\Comment{Correct mean}
	\State $   \Sigma_t = (I-K_t H_t)\bar{\Sigma}_t$\;
	\Comment{Correct covar}
	\State {\bf Result: }$(\mu_t, \Sigma_t)$
\end{algorithmic}
\end{algorithm}

\subsubsection{EKF Results}
The accuracy of the linearity assumption in the EKF is strongly dependent on the variance. Linearizing around the mean is only valid for points that are near the mean. So if the variance is low, as in Figure \ref{fig:EKF_low_var}, the EKF provides an accurate estimate of the true state. If there is high variance in the prior distribution, as in Figure \ref{fig:EKF_high_var}, the EKF will propagate forward a poor estimate of a poor estimate, and can become very ineffective. Advantages of EKF over other nonlinear variants of the Kalman filter include its relative computational efficiency.

%\FloatBarrier
\begin{figure}[H]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{EKF_low_var.png}
  \caption{EKF With Low Variance}
  \label{fig:EKF_low_var}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{EKF_high_var.png}
  \caption{EKF With High Variance}
  \label{fig:EKF_high_var}
\end{subfigure}
\caption{EKF performance for different levels of uncertainty \cite{Xmisc}.}
\label{fig:EKF_variance}
\end{figure}
%\FloatBarrier
\subsubsection{More on EKF}

These following resources provide more insights into this topic.

\href{http://www.negenborn.net/kal_loc/thesis.pdf}{Robot Localization and Kalman Filters} Rudy Negenborn.


\href{https://link.springer.com/article/10.1007/s12046-017-0692-y}{Implementation of extended Kalman filter-based simultaneous
localization and mapping: a point feature approach} Manigandan Nagarajan SanthanakrishnanE, John Bosco Balaguru RayappanRamkumar Kannan.


Locating a two-wheel robot using extended kalman filter by Javad Zolghadr and Yuanli Cai. (This can be found at Google)


\href{https://www.cse.sc.edu/~terejanu/files/tutorialEKF.pdf}{Extended Kalman Filter Tutorial} by Gabriel A. Terejanu, University at Buffalo

\href{https://ags.cs.uni-kl.de/fileadmin/inf_ags/opt-ss12/lec10_opt.pdf}{Using the Kalman filter
Extended Kalman filter} by Doz. G. Bleser and Prof. Stricker

(Summary of extended kalman filter can be found in this one)




\subsection{Unscented Kalman Filter (UKF)}

Where in EKF, a Gaussian prediction is propagated through a simplified dynamic model, in UKF an approximated belief is propagated through the correct nonlinear model. This is accomplished by choosing points near the mean, called sigma points, transforming these points using the nonlinear model, and computing a posterior Gaussian distribution using these transformed sigma points. The differences between the treatment on nonlinearities in the EKF and UKF are illustrated in Figure \ref{fig:EKF_vs_UKF_transform}.

%\FloatBarrier
\begin{figure}[t]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.75\linewidth]{EKF_transform.PNG}
  \caption{EKF Transform}
  \label{fig:EKF_transform}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{UKF_transform.PNG}
  \caption{UKF Transform}
  \label{fig:UKF_transform}
\end{subfigure}
\caption{Transforms from prior to posterior for (a) EKF \cite{Xmisc} and (b) UKF \cite{Xmisc}. The EKF handles nonlinearities by linearizing at a single point. The UKF instead computes values of the nonlinear function at many sigma points and fits a Gaussian to the resulting points.}
\label{fig:EKF_vs_UKF_transform}
\end{figure}
%\FloatBarrier


\subsubsection{Unscented transform}
Here we assume an $n$-dimensional Gaussian $\mathcal{N}(\mu,\Sigma)$. Instead of linearizing about the mean, the unscented transform propagates ``sigma points''---samples chosen to represent the probability distribution---through the nonlinear function $g$. There are a total of $2n+1$ sigma points (numbered $i = 0, \dots, 2n$): one point at the mean and two points symmetrically  distributed according to the covariance in each of the $n$ dimensions.
\begin{align}
\begin{split}
\mathcal{X}^{[0]} &= \mu \\
\mathcal{X}^{[i]} &= \mu + \left(\sqrt{(n+ \lambda)\Sigma}\right)_i \qquad \text{for $i = 1, \dots, n$} \\
\mathcal{X}^{[i]} &= \mu - \left(\sqrt{(n+ \lambda)\Sigma}\right)_{i-n} \qquad \text{for $i = n+1, \dots, 2n$},
\end{split}
\label{UKFsigpts}
\end{align}
where $\lambda = \alpha^2(n+\kappa) - n$, and $\alpha$ and $\kappa$ parameterize the distance from the off-mean sigma points $\mathcal{X}^{[i]}$ from the mean $\mathcal{X}^{[0]}$. In calculating the sigma points (for instance in Algorithm \ref{UKF_ALG}), we use the notation $\gamma = \sqrt{n + \lambda}$.
Each sigma point is associated with two weights: $w_m^{[i]}$, used to compute the mean, and $w_c^{[i]}$, used to compute the covariance.
\begin{align}
\begin{split}
w_m^{[0]} &= \frac{\lambda}{n + \lambda}, \qquad w_c^{[0]} = \frac{\lambda}{n + \lambda} + (1 - \alpha^2 + \beta) \\
w_m^{[i]} &= w_c^{[i]} = \frac{1}{2(n+\lambda)} \qquad \text{for $i = 1, \dots, 2n$}.
\end{split}
\label{UKFweights}
\end{align}
A value of $\beta = 2$ is typically used \cite{thrun2005probabilistic}.
After computing the sigma points, we pass them through the nonlinear dynamics function,
\begin{equation}
	 \mathcal{Y}^{[i]} = g( \mathcal{X}^{[i]})
\end{equation}
Then given the weights we have chosen, we are able to recover the mean and covariance of the distribution,
\begin{align}
\begin{split}
\mu' &= \sum_{i=0}^{2n} w_m^{[i]}\mathcal{Y}^{[i]}\\
\Sigma' &= \sum_{i=0}^{2n} w_c^{[i]}(\mathcal{Y}^{[i]}-\mu')(\mathcal{Y}^{[i]}-\mu')^{T}
\end{split}
\end{align}

\subsubsection{UKF Algorithm}
The UKF algorithm takes the same inputs as the other variants of the Kalman filter: the probability distribution of the state at the previous timestep, as well as the current control input and measurement. At each time step, we compute the sigma points and then propagate them through the dynamics equation:
\begin{equation}
\bar{\mathcal{X}}^*_t = g(u_t, \mathcal{X}_{t-1})
\end{equation}
Note that $\bar{\mathcal{X}}^*_t$ do not necessarily correspond to a Gaussian distribution (i.e., maintain their symmetry) after this nonlinear transformation. Then, from $\bar{\mathcal{X}}^*_t$, we can compute the \textit{predicted belief} $(\bar{\mu}_t, \bar{\Sigma}_t)$ using the weighting as shown in \eqref{UKFweights}:
\begin{align}
\begin{split}
\bar{\mu}_t &= \sum_{i=0}^{2n} w_m^{[i]}\bar{\mathcal{X}_t^*}^{[i]} \\
\bar{\Sigma}_t &= \sum_{i=0}^{2n} w_c^{[i]}\left(\bar{\mathcal{X}_t^*}^{[i]} -\bar{\mu}_t\right)\left(\bar{\mathcal{X}_t^*}^{[i]} -\bar{\mu}_t\right)^T + R_t
\end{split}
\end{align}
We compute the predicted sigma-points $\bar{\mathcal{X}}_t$ from the predicted belief $(\bar{\mu}_t, \bar{\Sigma}_t)$ as follows, using the same rules as in \eqref{UKFsigpts}.
Propagating the sigma points through the nonlinear measurement function gives
\begin{equation}
\bar{\mathcal{Z}}_t = h(\bar{\mathcal{X}}_t),
\end{equation}
from which the predicted observation can be computed:
\begin{align}
\begin{split}
\hat{z}_t &=  \sum_{i=0}^{2n} w_m^{[i]}\bar{\mathcal{Z}_t}^{[i]} \\
S_t &= \sum_{i=0}^{2n} w_c^{[i]}\left(\bar{\mathcal{Z}_t}^{[i]} -\hat{z}_t\right)\left(\bar{\mathcal{Z}_t}^{[i]} -\hat{z}_t\right)^T + Q_t
\\\bar{\Sigma}_t^{x,z} &= \sum_{i=0}^{2n} w_c^{[i]}\left(\bar{\mathcal{X}_t}^{[i]} -\bar{\mu}_t\right)\left(\bar{\mathcal{Z}_t}^{[i]} -\hat{z}_t\right)^T
\end{split}
\end{align}
The quantity $S_t$ represents the uncertainty as the $(H_t \bar{\Sigma}_t H_t^T + Q_t)$ term in the EKF algorithm, while $\bar{\Sigma}_t^{x,z}$ describes the cross-covariance between the state and the measurement. Together, these two terms contribute to the Kalman gain:
\begin{equation}
K_t = \bar{\Sigma}_t^{x,z}S_t^{-1}
\end{equation}
Then we can update the belief function:
\begin{align}
\begin{split}
\mu_t &= \bar{\mu}_t + K_t(z_t - \hat{z}_t) \\
\Sigma_t &= \bar{\Sigma}_t  - K_t S_t K_t^T
\end{split}
\end{align}

\begin{algorithm}[H]
\caption{Unscented Kalman Filter}
\begin{algorithmic}[1]
    \State {\bf Data: }$(\mu_{t-1}, \Sigma_{t-1}), u_t, z_t$
    \State {\bf Result: }$\left(\mu_t, \Sigma_t\right)$
    \State $ \mathcal{X}_{t-1} = \left(\mu_{t-1} \qquad \mu_{t-1} + \gamma \sqrt{\Sigma_{t-1}}\qquad \mu_{t-1} - \gamma \sqrt{\Sigma_{t-1}}\right)$ \;
    \Comment{Form sigma points \eqref{UKFsigpts}}
    \State $\bar{\mathcal{X}}^*_t = g(u_t, \mathcal{X}_{t-1})$ \;
    \Comment{Propagate through dynamics}
    \State $\bar{\mu}_t = \sum_{i=0}^{2n} w_m^{[i]}\bar{\mathcal{X}_t^*}^{[i]}$ \;
    \Comment{Predict mean}
    \State $\bar{\Sigma}_t = \sum_{i=0}^{2n} w_c^{[i]}\left(\bar{\mathcal{X}_t^*}^{[i]} -\bar{\mu}_t\right)\left(\bar{\mathcal{X}_t^*}^{[i]} -\bar{\mu}_t\right)^T + R_t$ \;
    \Comment{Predict covar}
    \State $ \bar{\mathcal{X}}_{t} = \left(\bar{\mu}_{t} \qquad \bar{\mu}_{t}  + \gamma \sqrt{\bar{\Sigma}_t}\qquad \bar{\mu}_{t}  - \gamma \sqrt{\bar{\Sigma}_t}\right)$ \;
    \Comment{Predict sigma points}
    \State $\bar{\mathcal{Z}}_t = h(\bar{\mathcal{X}}_t)$\;
    \Comment{Propagate through nonlinear measurement}
    \State $\hat{z}_t =  \sum_{i=0}^{2n} w_m^{[i]}\bar{\mathcal{Z}_t}^{[i]}$ \;
    \Comment {Predicted observation}
    \State $S_t = \sum_{i=0}^{2n} w_c^{[i]}\left(\bar{\mathcal{Z}_t}^{[i]} -\hat{z}_t\right)\left(\bar{\mathcal{Z}_t}^{[i]} -\hat{z}_t\right)^T + Q_t$ \;
    \Comment{Uncertainty}
    \State $\bar{\Sigma}_t^{x,z} = \sum_{i=0}^{2n} w_c^{[i]}\left(\bar{\mathcal{X}_t}^{[i]} -\bar{\mu}_t\right)\left(\bar{\mathcal{Z}_t}^{[i]} -\hat{z}_t\right)^T$ \;
    \Comment{Cross-covar}
    \State $K_t = \bar{\Sigma}_t^{x,z}S_t^{-1}$ \;
    \Comment{Kalman gain}
    \State $ \mu_t = \bar{\mu}_t + K_t(z_t - \hat{z}_t)$ \;
    \Comment{Correct mean}
    \State $\Sigma_t = \bar{\Sigma}_t  - K_t S_t K_t^T$ \;
    \Comment{Correct covar}
    \State {\bf Return: }$(\mu_t, \Sigma_t)$
\end{algorithmic}
\label{UKF_ALG}
\end{algorithm}

\subsubsection{UKF Results}
%\FloatBarrier
\begin{figure}[t]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{UKF_low_var.png}
  \caption{UKF with Low Variance}
  \label{fig:UKF_low}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{UKF_high_var.png}
  \caption{UKF with High Variance}
  \label{fig:UKF_high}
\end{subfigure}
\caption{The performance of the UKF compared to the EKF for different levels of uncertainty \cite{Xmisc}.}
\label{fig:UKF_variance}
\end{figure}
%\FloatBarrier
While the asymptotic complexities for the UKF and EKF algorithms are equivalent, the EKF is typically marginally faster than the UKF in practice. However, the UKF has the advantage if not requiring computation of Jacobians, which can sometimes pose an analytic challenge. The UKF is much less sensitive to variance than the EKF because it propagates forward the exact nonlinear motion and measurement processes. As Figure \ref{fig:UKF_variance} shows, the UKF and EKF perform very similarly with low variance, but the UKF outperforms the EKF with high variance.


\section{Nonparametric Filters}
Nonparametric filters do not make any assumptions on the robot's belief distribution. Instead, they approximate the distribution discretely with a finite number of values. The accuracy of the representation depends on the number of values used, which results in a trade-off between expressiveness and computational burden. They are more robust to nonlinearities and discontinuities in the inference space, but also tend to be more complicated and time-consuming to implement.

\subsection{Histogram Filter}

Histogram filters are one way of finding a discrete approximation of a continuous distribution of beliefs. They first decompose a continuous space into finitely many bins,
\begin{equation}
\mathtt{dom}(X_t) = x_{1,t} \cup x_{2,t} \cup ... x_{k,t}
\end{equation}
then each region $x_{k,t}$ is assigned a probability $p_{k,t}$, which is approximated in a piecewise scheme based on the assumption of uniform density in each bin.
\begin{equation}
p(x_t) = \frac{p_{k,t}}{\lvert x_{k,t} \rvert},\quad x_t \in x_{k,t}
\end{equation}
To calculate the probability distribution, the motion and measurement models are discretized, and the central mass in each region is chosen as its representative state $\hat x_{k,t}$,
\begin{equation}
\hat x_{k,t} = \lvert x_{k,t} \rvert ^{-1}\int_{x_{k,t}}x_t d x_t
\end{equation}
Given a state $x_{k,t}$, the conditional probability $p(z_t \mid x_{k,t})$ is set equal to the probability of that measurement conditional on the representative state in that region, $p(z_t \mid \hat x_{k,t})$. A similar process is used to approximate the state transition probabilities by applying Bayes' law,
\begin{equation}
p(x_{k,t} \mid u_t, x_{i,t-1}) = \eta \lvert x_{k,t} \rvert p(\hat x_{k,t} \mid u_t, \hat x_{i,t-1})
\end{equation}
Finally, we execute a discrete Bayes' filter on the discretized probabilities to estimate the full belief distribution. A histogram representation of a robot's belief is shown in Figure \ref{fig:Histogram_belief}.


%\FloatBarrier
\begin{figure}[t]
\centering
\includegraphics[width=1\linewidth]{histogram_belief.png}
\caption{Histogram representation of belief from initial sensor measurement from \cite{thrun2005probabilistic}.}
\label{fig:Histogram_belief}
\end{figure}
%\FloatBarrier


\subsection{Particle Filter}
\subsubsection{Approximating with Particles}
Particle filters differ from Kalman filters or any parametric filters in the sense that it does not assume any type of belief distribution. Instead, particle filters can approximate any PDF using a large numbers of "particles". To approximate a PDF with particles, particles are generated based on the relative likelihood of these samples directly. For example, given a random variable $X$ with PDF $Pr[X = 0] = 0.1$ and $Pr[X=1] = 0.9$, $10\%$ of the particles will have value 0 and $90\%$ of the particles will have value 1.
\subsubsection{Particle Filter Algorithm}
This intuition can be formally shown as the following: let a particle filter approximates the posterior distribution with a finite number of particles, denoted as
\begin{equation}
	\mathcal{X}_t = x_t^{[1]}, x_t^{[2]},..., x_t^{[M]}
\end{equation}
with each $x_t^{[k]}$ representing a hypothesis of what the true world state would be at time $t$. The denser the particles, the higher the probability of landing in a region. 

The algorithm operates iteratively: assuming we have $M$ particles, given $\mathcal{X}_{t-1}$, we construct the next particle set $\mathcal{X}_t$ by first construct a predicted particle set, then use the measurement result to correct the belief state. First, a predicted particle set is constructed by drawing samples from the current belief state $p(x_t| u_t, x^{[m]}_{t-1})$. Meanwhile, the probability we observe a particular measurement conditional on the state, $w^{[m]}_t$, is also calculated. Next, the correction step, often referred to as resampling with replacement, incorporates our measurements into the calculation. A corrected set of particles are generated by drawing a particle $i$ from the predicted particle set with probability proportional to $w^{[i]}_t$. 

After resampling, particles are distributed as
\begin{equation}
	bel(X_t) = \eta P(z_t \mid x_t^{[m]})\overline{bel}(X_t)
\end{equation}
for $M \rightarrow \infty$. That is, in the limit, we recover the distribution of the true nonlinear filter. ($M \approx 1000$ achieves acceptable accuracy in practice). A few iterations of the particle filter algorithm for robot localization are shown in Figure \ref{fig:Particle_filter}.

Note that after several resampling steps, particles will often collapsed into very few states. This situation is called particle deprivation. To correct this, we can inject $n$ random particles into the corrected particle set after each iteration. 

\begin{algorithm}[H]
\caption{Particle Filter}
\KwData{$\mathcal{X}_{t-1}, u_t, z_t$}
\KwResult{$\mathcal{X}_t$}
$\bar{\mathcal{X}}_t = X_t = \emptyset$\;

\For{$m=1$ \KwTo $M$}{
sample $x_t^{[m]} \sim p(x_t \mid u_t, x_{t-1}^{[m]})$\;
$w_t^{[m]} = p(z_t \mid x_t^{[m]})$\;
$\bar{\mathcal{X}}_t = \bar{\mathcal{X}}_t \cup \left(x_t^{[m]}, w_t^{[m]}\right)$\;
}
\For{$i=1$ \KwTo $M$}{
draw $i$ with probability $\propto w_t^{[i]}$\;
add $x_t^{[i]}$ to $\mathcal{X}_t$\;
}
{\bf Return: }$\mathcal{X}_t$
\end{algorithm}

%\FloatBarrier
\begin{figure}[p]
\centering
\includegraphics[width=0.88\linewidth]{particle_localization.png}
\caption{Particle filter used for robot localization from \cite{thrun2005probabilistic}: (a) Initial particles sampled uniformly over entire state space, (b) same set of particles from (a) after importance weighting with initial sensor measurement, (c) resampled particles from weighted distribution after motion, (d) importance weighting of new particle set with new sensor measurement, and (e) resampled particle set after further motion.}
\label{fig:Particle_filter}
\end{figure}
%\FloatBarrier

\section{Robot Localization}
Localization is the process of determining the correspondence between a robot's placement and the environment's map coordinates. Like before, a control input $u_t$ gives rise to a robot state $x_t$, which produces measurements $z_t$. The distinction is that this time, the map $m$ influences our measurements and possibly control parameters as well. Different situations thus may call for different filters. This influence is shown in the updated Bayes network (Hidden Markov Model) for robot localization in Figure \ref{fig:HMM_with_map}. Similarly, the influence of the map (door locations) can be seen in the measurement model $p(z \mid x)$ in Figures \ref{fig:Histogram_belief},
\ref{fig:Particle_filter}b, and \ref{fig:Particle_filter}d.

%\FloatBarrier
\begin{figure}[H]
\centering
\includegraphics[width=0.45\linewidth]{HMM_w_map.png}
\caption{Hidden Markov Model for robot localization, where a map informs sensor measurements and control actions \cite{Xmisc}.}
\label{fig:HMM_with_map}
\end{figure}
%\FloatBarrier

\subsection{A Taxonomy of Localization Problems}
    \subsubsection{Local vs Global Localization}
    The type of localization algorithm used is heavily depending on the information available at initialization and during a robot's operation.
    
    In \textit{position tracking}, the initial pose of the robot is known with certainty. This approach assumes that as the robot moves in its environment the pose error remains relatively small and concentrated near the robot's true pose. The EKF works well for this problem because it approximates the error using a unimodal (i.e. Gaussian) distribution.
    
    On the other hand, \textit{global localization} assumes the initial pose is unknown. In this scenario, the belief distribution is inherently multi-modal as the robot attempts to localize itself. In this case, non-parametric filters like histogram or particle filters are preferable. 
    
    A final case is that of the \textit{kidnapped robot}. In this case the initial pose is unknown and the robot can be "kidnapped" during its operation, i.e. a discontinuity may exist in its state $\mathbf{x}(t)$. This models the situation when a filter diverges to a significant enough degree that it must be reset. Hence, our localization algorithm should be capable of restarting from a different point/orientation in space. The kidnapped robot localization problem is best addressed with non-parametric, multi-hypothesis filters.
    
    \subsubsection{Static vs Dynamic Environments}
    Environmental changes are another important consideration in mobile robot localization. A \textit{static} environment assumes that the robot is the only object that moves. In contrast, a \textit{dynamic} environmental model allows other objects, such as people, to move as well. This problem is usually addressed by augmenting the state vector to include the movement of dynamic entities, or by filtering the sensor data to remove the effects of environment dynamics.
    
    \subsubsection{Passive vs Active Approaches}
    Localization problems can be further split into passive and active depending on whether the localization algorithm can control the motion of the robot. \textit{Passive} localization assumes that a single module takes measurements, and the robot's motion is unrelated to its localization process. 
    
    A more sophisticated approach is \textit{active} localization, where the robot's movement is aimed (at least partly) toward improving its understanding of the environment. For example, a robot in a corner will tend to reorient itself to face the rest of the room, so it can collect environmental information as it moves along the wall. In the same situation, a passively localized robot may simply slide along with its camera facing the wall. However, since active approaches require control over the robot, they tend to be insufficient in practice. They are often combined with passive techniques that operate when the robot is performing tasks other than localization. 
    
    \subsubsection{Single Robot vs Multi-Robot}
    A final consideration in the localization problem is the number of robots involved. \textit{Single-robot localization} is the most commonly studied and utilized approach. Only a single robot is used in this scheme, and this approach offers the advantage of having all data collected in a single platform.
    
    \textit{Multi-robot localization} occurs when a team of robots share information in such a way that one robot's belief can be used to influence another robot's belief if the relative location between robots is known. 




\printbibliography

\subsubsection*{Contributors}
Winter 2019: Spencer Diehl, Jennifer Lin, Georgia Murray, Akshay Rajagopal, Mimi Su, JQ Zhang \\
Winter 2018: Arthur Binstein, Anqi Fu, Trevor Halsted, Scott Hemley, Alexander Hobbs, Jialong Wang

\end{document}
